{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bb32bbd-d6bf-4c87-9832-764adff41682",
   "metadata": {},
   "source": [
    "# Tutorial on CNN Classifiers with Pytorch Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed463f14",
   "metadata": {},
   "source": [
    "Code reference: https://pytorch-lightning.readthedocs.io/en/latest/notebooks/course_UvA-DL/04-inception-resnet-densenet.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfab9624-2366-41c3-94fe-88a016a12936",
   "metadata": {},
   "source": [
    "## Python imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cede98-10c3-4b87-83a0-83680e962288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from types import SimpleNamespace\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import seaborn as sns\n",
    "import tabulate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "\n",
    "# %matplotlib inline\n",
    "from IPython.display import HTML, display, set_matplotlib_formats\n",
    "from PIL import Image\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "set_matplotlib_formats(\"svg\", \"pdf\")  # For export\n",
    "matplotlib.rcParams[\"lines.linewidth\"] = 2.0\n",
    "sns.reset_orig()\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fc3685-f319-4274-b8c2-d1e1d9ea48eb",
   "metadata": {},
   "source": [
    "## Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b25b2cb-5067-4655-9efd-5d40f06752fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
    "DATASET_PATH = \"/home/kti03/Data\"\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"saved_models/ConvNets\"\n",
    "\n",
    "\n",
    "# Function for setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.determinstic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304901c6-20c3-4780-939f-206f2ef2a57b",
   "metadata": {},
   "source": [
    "## Load data and model checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8c6b59-977a-42c5-9352-71790ff9fd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Github URL where saved models are stored for this tutorial\n",
    "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial5/\"\n",
    "# Files to download\n",
    "pretrained_files = [\n",
    "    \"GoogleNet.ckpt\",\n",
    "    \"ResNet.ckpt\",\n",
    "    \"ResNetPreAct.ckpt\",\n",
    "    \"DenseNet.ckpt\",\n",
    "    \"tensorboards/GoogleNet/events.out.tfevents.googlenet\",\n",
    "    \"tensorboards/ResNet/events.out.tfevents.resnet\",\n",
    "    \"tensorboards/ResNetPreAct/events.out.tfevents.resnetpreact\",\n",
    "    \"tensorboards/DenseNet/events.out.tfevents.densenet\",\n",
    "]\n",
    "# Create checkpoint path if it doesn't exist yet\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "\n",
    "# For each file, check whether it already exists. If not, try downloading it.\n",
    "for file_name in pretrained_files:\n",
    "    file_path = os.path.join(CHECKPOINT_PATH, file_name)\n",
    "    if \"/\" in file_name:\n",
    "        os.makedirs(file_path.rsplit(\"/\", 1)[0], exist_ok=True)\n",
    "    if not os.path.isfile(file_path):\n",
    "        file_url = base_url + file_name\n",
    "        print(f\"Downloading {file_url}...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "        except HTTPError as e:\n",
    "            print(\n",
    "                \"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\",\n",
    "                e,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40406d68-a0fd-4e6c-b0f3-940a183b5846",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CIFAR10(root=DATASET_PATH, train=True, download=True)\n",
    "DATA_MEANS = (train_dataset.data / 255.0).mean(axis=(0, 1, 2))\n",
    "DATA_STD = (train_dataset.data / 255.0).std(axis=(0, 1, 2))\n",
    "print(\"Data mean\", DATA_MEANS)\n",
    "print(\"Data std\", DATA_STD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71b4712-cdd0-4927-9d4b-975f487ee966",
   "metadata": {},
   "source": [
    "We will use this information to define a transforms.Normalize module which will normalize our data accordingly. Additionally, we will use data augmentation during training. This reduces the risk of overfitting and helps CNNs to generalize better. Specifically, we will apply two random augmentations.\n",
    "\n",
    "First, we will flip each image horizontally by a chance of 50% (transforms.RandomHorizontalFlip). The object class usually does not change when flipping an image, and we don't expect any image information to be dependent on the horizontal orientation. This would be however different if we would try to detect digits or letters in an image, as those have a certain orientation.\n",
    "\n",
    "The second augmentation we use is called transforms.RandomResizedCrop. This transformation scales the image in a small range, while eventually changing the aspect ratio, and crops it afterward in the previous size. Therefore, the actual pixel values change while the content or overall semantics of the image stays the same.\n",
    "\n",
    "We will randomly split the training dataset into a training and a validation set. The validation set will be used for determining early stopping. After finishing the training, we test the models on the CIFAR test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4f52b4-978d-41bd-8779-38c1509f41ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(DATA_MEANS, DATA_STD)])\n",
    "# For training, we add some augmentation. Networks are too powerful and would overfit.\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomResizedCrop((32, 32), scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(DATA_MEANS, DATA_STD),\n",
    "    ]\n",
    ")\n",
    "# Loading the training dataset. We need to split it into a training and validation part\n",
    "# We need to do a little trick because the validation set should not use the augmentation.\n",
    "train_dataset = CIFAR10(root=DATASET_PATH, train=True, transform=train_transform, download=True)\n",
    "val_dataset = CIFAR10(root=DATASET_PATH, train=True, transform=test_transform, download=True)\n",
    "pl.seed_everything(42)\n",
    "train_set, _ = torch.utils.data.random_split(train_dataset, [45000, 5000])\n",
    "pl.seed_everything(42)\n",
    "_, val_set = torch.utils.data.random_split(val_dataset, [45000, 5000])\n",
    "\n",
    "# Loading the test set\n",
    "test_set = CIFAR10(root=DATASET_PATH, train=False, transform=test_transform, download=True)\n",
    "\n",
    "# We define a set of data loaders that we can use for various purposes later.\n",
    "train_loader = data.DataLoader(train_set, batch_size=128, shuffle=True, drop_last=True, pin_memory=True, num_workers=4)\n",
    "val_loader = data.DataLoader(val_set, batch_size=128, shuffle=False, drop_last=False, num_workers=4)\n",
    "test_loader = data.DataLoader(test_set, batch_size=128, shuffle=False, drop_last=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464333a2-acd2-4f85-a4e3-ddd69f6537e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, _ = next(iter(train_loader))\n",
    "print(\"Batch mean\", imgs.mean(dim=[0, 2, 3]))\n",
    "print(\"Batch std\", imgs.std(dim=[0, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c02e369-62ec-48c4-8ed5-77411ba7dfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_IMAGES = 4\n",
    "images = [train_dataset[idx][0] for idx in range(NUM_IMAGES)]\n",
    "orig_images = [Image.fromarray(train_dataset.data[idx]) for idx in range(NUM_IMAGES)]\n",
    "orig_images = [test_transform(img) for img in orig_images]\n",
    "\n",
    "img_grid = torchvision.utils.make_grid(torch.stack(images + orig_images, dim=0), nrow=4, normalize=True, pad_value=0.5)\n",
    "img_grid = img_grid.permute(1, 2, 0)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Augmentation examples on CIFAR10\")\n",
    "plt.imshow(img_grid)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195ac38f-4f5c-4641-af84-0f0146d37b2c",
   "metadata": {},
   "source": [
    "## Pytorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b5c99e-f0bb-43ac-8f67-bb032c901ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65030bd6-9bef-478e-8f94-e5872640d9b9",
   "metadata": {},
   "source": [
    "In PyTorch Lightning, we define pl.LightningModule's (inheriting from torch.nn.Module) that organize our code into 5 main sections:\n",
    "\n",
    "1. Initialization (__init__), where we create all necessary parameters/models\n",
    "2. Optimizers (configure_optimizers) where we create the optimizers, learning rate scheduler, etc.\n",
    "3. Training loop (training_step) where we only have to define the loss calculation for a single batch (the loop of optimizer.zero_grad(), loss.backward() and  optimizer.step(), as well as any logging/saving operation, is done in the background)\n",
    "4. Validation loop (validation_step) where similarly to the training, we only have to define what should happen per step\n",
    "5. Test loop (test_step) which is the same as validation, only on a test set.\n",
    "\n",
    "Therefore, we don't abstract the PyTorch code, but rather organize it and define some default operations that are commonly used. If you need to change something else in your training/validation/test loop, there are many possible functions you can overwrite (see the docs for details).\n",
    "\n",
    "Now we can look at an example of how a Lightning Module for training a CNN looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e454dc-50ae-4d0a-bf3e-3f5b7d537f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFARModule(pl.LightningModule):\n",
    "    def __init__(self, model_name, model_hparams, optimizer_name, optimizer_hparams):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            model_name - Name of the model/CNN to run. Used for creating the model (see function below)\n",
    "            model_hparams - Hyperparameters for the model, as dictionary.\n",
    "            optimizer_name - Name of the optimizer to use. Currently supported: Adam, SGD\n",
    "            optimizer_hparams - Hyperparameters for the optimizer, as dictionary. This includes learning rate, weight decay, etc.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Exports the hyperparameters to a YAML file, and create \"self.hparams\" namespace\n",
    "        self.save_hyperparameters()\n",
    "        # Create model\n",
    "        self.model = create_model(model_name, model_hparams)\n",
    "        # Create loss module\n",
    "        self.loss_module = nn.CrossEntropyLoss()\n",
    "        # Example input for visualizing the graph in Tensorboard\n",
    "        self.example_input_array = torch.zeros((1, 3, 32, 32), dtype=torch.float32)\n",
    "\n",
    "    def forward(self, imgs):\n",
    "        # Forward function that is run when visualizing the graph\n",
    "        return self.model(imgs)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # We will support Adam or SGD as optimizers.\n",
    "        if self.hparams.optimizer_name == \"Adam\":\n",
    "            # AdamW is Adam with a correct implementation of weight decay (see here\n",
    "            # for details: https://arxiv.org/pdf/1711.05101.pdf)\n",
    "            optimizer = optim.AdamW(self.parameters(), **self.hparams.optimizer_hparams)\n",
    "        elif self.hparams.optimizer_name == \"SGD\":\n",
    "            optimizer = optim.SGD(self.parameters(), **self.hparams.optimizer_hparams)\n",
    "        else:\n",
    "            assert False, f'Unknown optimizer: \"{self.hparams.optimizer_name}\"'\n",
    "\n",
    "        # We will reduce the learning rate by 0.1 after 100 and 150 epochs\n",
    "        scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100, 150], gamma=0.1)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # \"batch\" is the output of the training data loader.\n",
    "        imgs, labels = batch\n",
    "        preds = self.model(imgs)\n",
    "        loss = self.loss_module(preds, labels)\n",
    "        acc = (preds.argmax(dim=-1) == labels).float().mean()\n",
    "\n",
    "        # Logs the accuracy per epoch to tensorboard (weighted average over batches)\n",
    "        self.log(\"train_acc\", acc, on_step=False, on_epoch=True)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss  # Return tensor to call \".backward\" on\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        preds = self.model(imgs).argmax(dim=-1)\n",
    "        acc = (labels == preds).float().mean()\n",
    "        # By default logs it per epoch (weighted average over batches)\n",
    "        self.log(\"val_acc\", acc)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        preds = self.model(imgs).argmax(dim=-1)\n",
    "        acc = (labels == preds).float().mean()\n",
    "        # By default logs it per epoch (weighted average over batches), and returns it afterwards\n",
    "        self.log(\"test_acc\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a970c1-2f4e-432d-9881-c81c4af14713",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "\n",
    "\n",
    "def create_model(model_name, model_hparams):\n",
    "    if model_name in model_dict:\n",
    "        return model_dict[model_name](**model_hparams)\n",
    "    else:\n",
    "        assert False, f'Unknown model name \"{model_name}\". Available models are: {str(model_dict.keys())}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f564027e-9671-4589-981f-88a5b0269348",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_fn_by_name = {\"tanh\": nn.Tanh, \"relu\": nn.ReLU, \"leakyrelu\": nn.LeakyReLU, \"gelu\": nn.GELU}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d1ef63-b8f5-4a21-b77e-eb4cc9a3e73a",
   "metadata": {},
   "source": [
    "Besides the Lightning module, the second most important module in PyTorch Lightning is the Trainer. The trainer is responsible to execute the training steps defined in the Lightning module and completes the framework. Similar to the Lightning module, you can override any key part that you don't want to be automated, but the default settings are often the best practice to do. For a full overview, see the documentation. The most important functions we use below are:\n",
    "\n",
    "- trainer.fit: Takes as input a lightning module, a training dataset, and an (optional) validation dataset. This function trains the given module on the training dataset with occasional validation (default once per epoch, can be changed)\n",
    "- trainer.test: Takes as input a model and a dataset on which we want to test. It returns the test metric on the dataset.\n",
    "\n",
    "For training and testing, we don't have to worry about things like setting the model to eval mode (model.eval()) as this is all done automatically. See below how we define a training function for our models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c56923a-d832-41de-be91-621086d6ebe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name, save_name=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        model_name - Name of the model you want to run. Is used to look up the class in \"model_dict\"\n",
    "        save_name (optional) - If specified, this name will be used for creating the checkpoint and logging directory.\n",
    "    \"\"\"\n",
    "    if save_name is None:\n",
    "        save_name = model_name\n",
    "\n",
    "    # Create a PyTorch Lightning trainer with the generation callback\n",
    "    trainer = pl.Trainer(\n",
    "        default_root_dir=os.path.join(CHECKPOINT_PATH, save_name),  # Where to save models\n",
    "        # We run on a single GPU (if possible)\n",
    "        gpus=1 if str(device) == \"cuda:0\" else 0,\n",
    "        # How many epochs to train for if no patience is set\n",
    "        max_epochs=180,\n",
    "        callbacks=[\n",
    "            ModelCheckpoint(\n",
    "                save_weights_only=True, mode=\"max\", monitor=\"val_acc\"\n",
    "            ),  # Save the best checkpoint based on the maximum val_acc recorded. Saves only weights and not optimizer\n",
    "            LearningRateMonitor(\"epoch\"),\n",
    "        ],  # Log learning rate every epoch\n",
    "        progress_bar_refresh_rate=1,\n",
    "    )  # In case your notebook crashes due to the progress bar, consider increasing the refresh rate\n",
    "    trainer.logger._log_graph = True  # If True, we plot the computation graph in tensorboard\n",
    "    trainer.logger._default_hp_metric = None  # Optional logging argument that we don't need\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, save_name + \".ckpt\")\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(f\"Found pretrained model at {pretrained_filename}, loading...\")\n",
    "        # Automatically loads the model with the saved hyperparameters\n",
    "        model = CIFARModule.load_from_checkpoint(pretrained_filename)\n",
    "    else:\n",
    "        pl.seed_everything(42)  # To be reproducable\n",
    "        model = CIFARModule(model_name=model_name, **kwargs)\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "        model = CIFARModule.load_from_checkpoint(\n",
    "            trainer.checkpoint_callback.best_model_path\n",
    "        )  # Load best checkpoint after training\n",
    "\n",
    "    # Test best model on validation and test set\n",
    "    val_result = trainer.test(model, test_dataloaders=val_loader, verbose=False)\n",
    "    test_result = trainer.test(model, test_dataloaders=test_loader, verbose=False)\n",
    "    result = {\"test\": test_result[0][\"test_acc\"], \"val\": val_result[0][\"test_acc\"]}\n",
    "\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a27424-d50e-43d5-8f21-30dfc0ab69cd",
   "metadata": {},
   "source": [
    "## GoogLeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eb79d0-5360-4330-8dba-25cbc850b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.googlenet_pl import GoogleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f187524b-6226-4c9b-9c00-3240f0d89d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[\"GoogleNet\"] = GoogleNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbc7804-ff5d-4a8e-a673-724a73f57a68",
   "metadata": {},
   "source": [
    "Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dcb70b-5105-4a48-bc22-135384e0b5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "googlenet_model, googlenet_results = train_model(\n",
    "    model_name=\"GoogleNet\",\n",
    "    model_hparams={\"num_classes\": 10, \"act_fn_name\": \"relu\"},\n",
    "    optimizer_name=\"Adam\",\n",
    "    optimizer_hparams={\"lr\": 1e-3, \"weight_decay\": 1e-4},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e409455-f4c8-495a-b23a-54e586ccf701",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GoogleNet Results\", googlenet_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0119a88-140f-4b36-b1ec-49d3adba2b6a",
   "metadata": {},
   "source": [
    "## Tensorboard Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30165b4b-6cd2-4689-ad44-710c0b05fa86",
   "metadata": {},
   "source": [
    "A nice extra of PyTorch Lightning is the automatic logging into TensorBoard. To give you a better intuition of what TensorBoard can be used, we can look at the board that PyTorch Lightning has been generated when training the GoogleNet. TensorBoard provides an inline functionality for Jupyter notebooks, and we use it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11c3009-e45b-4450-90f5-d989112bf56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tensorboard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7280ada4-9b9d-4fa7-b656-7a114f86f941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opens tensorboard in notebook. Adjust the path to your CHECKPOINT_PATH!\n",
    "%tensorboard --logdir saved_models/ConvNets/tensorboards/GoogleNet/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c83ada-fb7a-4c86-9db0-7f9c5bd2d304",
   "metadata": {},
   "source": [
    "## DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de582123-9b84-4906-830c-be47a407b5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.densenet_pl import DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5343c7fd-e40c-482c-a9b0-592d84c0861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[\"DenseNet\"] = DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41fb533-eeb9-4785-904c-467912219af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_model, densenet_results = train_model(\n",
    "    model_name=\"DenseNet\",\n",
    "    model_hparams={\n",
    "        \"num_classes\": 10,\n",
    "        \"num_layers\": [6, 6, 6, 6],\n",
    "        \"bn_size\": 2,\n",
    "        \"growth_rate\": 16,\n",
    "        \"act_fn_name\": \"relu\",\n",
    "    },\n",
    "    optimizer_name=\"Adam\",\n",
    "    optimizer_hparams={\"lr\": 1e-3, \"weight_decay\": 1e-4},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae49bee0-4967-4a96-9e3f-ae7d5ed22f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DenseNet Results\", densenet_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1996fb1b-ec2c-411f-b2ef-a8c5775e4c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opens tensorboard in notebook. Adjust the path to your CHECKPOINT_PATH! Feel free to change \"ResNet\" to \"ResNetPreAct\"\n",
    "%tensorboard --logdir saved_models/ConvNets/tensorboards/DenseNet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d94f05-82b2-4877-bd91-9da7f06d0059",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
